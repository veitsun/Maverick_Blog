# 基于GPU资源共享的虚拟化研究

## 设备直通方案：

客户端操作系统接收到GPU调用请求，通过PCIe中断，切换上下文环境到宿主机操作系统。加载GPU的SR-IOV（Single Root I/O Virtualization）驱动，创建四个虚拟设备，生成四个VF(Virtual Function) 。通过VFIO驱动框架（帮助管理和分配虚拟设备，可在安全的，受IOMMU保护的环境中直接访问对用户空间的直接访问），将生成的VF分配给不同的虚拟机，让虚拟机直接访问虚拟设备。

这种方案实际上是由客户操作系统使用原生驱动和硬件，支持PCI/PCIe设备直通，提供接近原生的GPU性能。缺点是这种方案缺少必要的中间层来跟踪和维护GPU状态，不支持不同虚拟机之间进行数据实时迁移的虚拟机高级特性。且只能根据国产GPU芯片一分四的特性，最多支持四个虚拟机，灵活性低。





## API重定向方案：



这种方案主要是在库的层级上进行虚拟化。这种方法通过拦截客户操作系统中的GPU调用，并将其转发到宿主机或者远程机器上的GPU进行处理。拦截的GPU调用请求通过共享内存的方式或者网络通信的方式将请求重定向到宿主机的操作系统中。重定向的请求被宿主机处理，只有结果通过包装库传递给应用程序。这种重定向方法可以模拟GPU执行环境，不需要在客户机的操作系统中暴露物理GPU设备。

为了实现这种方案我们需要5个关键模块，分别是包装库，前端驱动，后端驱动，通信模块，管理模块。

包装库是一个与原生GPU库具有相同API，安装在客户机操作系统中，是为了在GPU调用请求到达虚拟机上客户操作系统中的GPU驱动之前从应用程序中拦截GPU API调用，并将截取的请求交付给前端驱动。

前端驱动和后端驱动分别放置在客户机操作系统和宿主机操作系统中，前端驱动将接受到的GPU调用请求的接口和参数进行封装和编码,打包成可传输的消息（序列化的二进制数据流），将序列化的二进制编码通过通信模块传递到后端驱动。前端驱动也需要接受后端驱动返回的计算结果，将其传递给客户机应用程序上，模拟本地GPU的响应。

后端驱动将接收到的二进制编码进行解析，还原为原始的API调用，将解析出的调用和参数传递给物理GPU驱动进行计算，并将计算结果（如渲染后的图像或计算数据）编码，将编码通过通信模块传递回前端驱动。后端驱动还需要将自身可以正常使用的GPU设备信息注册到管理器中。在面对前端驱动传递过来的请求，为每个请求分配独立的服务线程，后端驱动统一管理本地GPU资源，按照一定的策略提供GPU资源，并将由于API调用修改的相关软硬件状态更新到管理器中GPU状态信息表。

通信模块是为了实现虚拟机和宿主机之间进行通信，选择通信策略，为虚拟化提供更高层语义的支持，如果宿主机和虚拟机在同一个物理机上，那么可以通过共享内存或者虚拟化专用通道进行数据交互，如果是进行云计算，物理GPU在远程的话，那么可以通过TCP/IP  RPC等网络通信方式进行数据的交互。

管理模块维护GPU的状态信息，在管理端维护一个GPU状态信息表。将GPU算力资源进行隔离，划分，调度。在管理模块实现对GPU资源的统一管理，包括动态调度，负载均衡和故障恢复。动态调度根据用户所占的资源空闲时间到达一定程度时，进行资源回收，依据高级调度算法进行资源调度。负载均衡可以在某个切片GPU计算压力过大的时候，调整计算负载，通过动态调度来选择合适的GPU资源来分散局部压力。故障恢复可以在某个切片GPU出现故障的时候，将任务重新转移到其他的可用GPU资源上面。

这种方案因为上层封装库升级快，中间层驱动需要不断对其进行适配，成本高；难以涵盖所有场景，隔离不准确；安全性低，用户可以绕过限制；无法提供算例精准限制的能力。

潜在的研究方向：

1，在后端驱动中，确保多个客户机的请求在物理GPU上安全隔离（可以通过上下文切换或者是硬件支持）

2，在通信模块，可以将多个小规模的GPU调用请求合并传输，通过共享内存直接映射客户机与宿主机的内存，避免数据复制。

3，在管理模块，研究动态资源分配方法，能够根据负载需求实时调整GPU资源的分配。

4， 在安全性上，研究出强大的隔离机制，防止侧信道攻击，创建安全的虚拟机监控程序和改进虚拟GPU驱动程序的安全性。

5，在GPU池化时，屏蔽底层GPU异构资源细节，分离上层AI 框架应用和底层GPU类型的耦合性。并且研究出一套算力隔离、故障隔离，都租户隔离的隔离方案

6，研究如何减小数据传输开销，和上下文切换开销

7，现有的容器运行时可能不支持动态分配，如何与虚拟化技术结合，实现更灵活的资源管理。
