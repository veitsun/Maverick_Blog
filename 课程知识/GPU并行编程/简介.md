# 简介

## 局部坐标与全局坐标映射

cuda 用四个内建变量标识线程，线程块的位置和大小

## block

为什么要划分 block ： 因为要实现硬件无关性

## warp

warp 是作为调度单位

每个线程块是被分为多个包含 32 个线程的线程束执行。

线程束中的线程 SIMD 中执行（N条执行路径，1/N 的吞吐量）

最多5层 if 嵌套，性能降至最低

## 线程块粒度的考虑

对于 Fermi 架构， 每个SM最多 1536 个线程，也就是说 16 * 16 可以更好的占满

# 如何提升内存的访问效率

提高计算量

提高利用率

合理利用内存层次结构

## cuda 的共享内存

共享内存的访问速度要比全局内存快（10倍）
